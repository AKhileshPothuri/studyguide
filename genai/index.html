
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://akhileshpothuri.github.io/learnwithakhilesh/genai/">
      
      
        <link rel="prev" href="../neural_networks/">
      
      
        <link rel="next" href="../research/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.12">
    
    
      
        <title>GenAI - Akhilesh's Study Guide</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.2afb09e1.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#generative-ai" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Akhilesh&#39;s Study Guide" class="md-header__button md-logo" aria-label="Akhilesh's Study Guide" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Akhilesh's Study Guide
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              GenAI
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Akhilesh&#39;s Study Guide" class="md-nav__button md-logo" aria-label="Akhilesh's Study Guide" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Akhilesh's Study Guide
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml_prep/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Machine Learning
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../neural_networks/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Neural Networks
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    GenAI
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    GenAI
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#core-concepts" class="md-nav__link">
    <span class="md-ellipsis">
      Core Concepts
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Core Concepts">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-is-generative-ai" class="md-nav__link">
    <span class="md-ellipsis">
      What is Generative AI?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-types-of-generative-models" class="md-nav__link">
    <span class="md-ellipsis">
      Key Types of Generative Models
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#large-language-models-llms" class="md-nav__link">
    <span class="md-ellipsis">
      Large Language Models (LLMs)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Large Language Models (LLMs)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#transformer-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention-mechanism" class="md-nav__link">
    <span class="md-ellipsis">
      Attention Mechanism
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-llm-families" class="md-nav__link">
    <span class="md-ellipsis">
      Key LLM Families
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fine-tuning-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      Fine-Tuning Techniques
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Fine-Tuning Techniques">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#supervised-fine-tuning-sft" class="md-nav__link">
    <span class="md-ellipsis">
      Supervised Fine-Tuning (SFT)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameter-efficient-fine-tuning-peft" class="md-nav__link">
    <span class="md-ellipsis">
      Parameter-Efficient Fine-Tuning (PEFT)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Parameter-Efficient Fine-Tuning (PEFT)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lora-low-rank-adaptation" class="md-nav__link">
    <span class="md-ellipsis">
      LoRA (Low-Rank Adaptation)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qlora-quantized-lora" class="md-nav__link">
    <span class="md-ellipsis">
      QLoRA (Quantized LoRA)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fine-tuning-with-unsloth" class="md-nav__link">
    <span class="md-ellipsis">
      Fine-tuning with Unsloth
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prompt-engineering-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      Prompt Engineering Techniques
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#multimodal-models" class="md-nav__link">
    <span class="md-ellipsis">
      Multimodal Models
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Multimodal Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#architectures" class="md-nav__link">
    <span class="md-ellipsis">
      Architectures
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#models" class="md-nav__link">
    <span class="md-ellipsis">
      Models
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deployment-and-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      Deployment and Optimization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Deployment and Optimization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#quantization" class="md-nav__link">
    <span class="md-ellipsis">
      Quantization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#knowledge-distillation" class="md-nav__link">
    <span class="md-ellipsis">
      Knowledge Distillation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#my-notes" class="md-nav__link">
    <span class="md-ellipsis">
      My Notes
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../research/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Research Papers
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../external_links/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Useful Links
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#core-concepts" class="md-nav__link">
    <span class="md-ellipsis">
      Core Concepts
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Core Concepts">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-is-generative-ai" class="md-nav__link">
    <span class="md-ellipsis">
      What is Generative AI?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-types-of-generative-models" class="md-nav__link">
    <span class="md-ellipsis">
      Key Types of Generative Models
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#large-language-models-llms" class="md-nav__link">
    <span class="md-ellipsis">
      Large Language Models (LLMs)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Large Language Models (LLMs)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#transformer-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#attention-mechanism" class="md-nav__link">
    <span class="md-ellipsis">
      Attention Mechanism
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-llm-families" class="md-nav__link">
    <span class="md-ellipsis">
      Key LLM Families
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fine-tuning-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      Fine-Tuning Techniques
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Fine-Tuning Techniques">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#supervised-fine-tuning-sft" class="md-nav__link">
    <span class="md-ellipsis">
      Supervised Fine-Tuning (SFT)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameter-efficient-fine-tuning-peft" class="md-nav__link">
    <span class="md-ellipsis">
      Parameter-Efficient Fine-Tuning (PEFT)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Parameter-Efficient Fine-Tuning (PEFT)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lora-low-rank-adaptation" class="md-nav__link">
    <span class="md-ellipsis">
      LoRA (Low-Rank Adaptation)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qlora-quantized-lora" class="md-nav__link">
    <span class="md-ellipsis">
      QLoRA (Quantized LoRA)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fine-tuning-with-unsloth" class="md-nav__link">
    <span class="md-ellipsis">
      Fine-tuning with Unsloth
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prompt-engineering-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      Prompt Engineering Techniques
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#multimodal-models" class="md-nav__link">
    <span class="md-ellipsis">
      Multimodal Models
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Multimodal Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#architectures" class="md-nav__link">
    <span class="md-ellipsis">
      Architectures
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#models" class="md-nav__link">
    <span class="md-ellipsis">
      Models
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deployment-and-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      Deployment and Optimization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Deployment and Optimization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#quantization" class="md-nav__link">
    <span class="md-ellipsis">
      Quantization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#knowledge-distillation" class="md-nav__link">
    <span class="md-ellipsis">
      Knowledge Distillation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#my-notes" class="md-nav__link">
    <span class="md-ellipsis">
      My Notes
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="generative-ai">Generative AI</h1>
<p>This section covers Generative AI models, fine-tuning techniques, prompting strategies, and related concepts.</p>
<h2 id="core-concepts">Core Concepts</h2>
<h3 id="what-is-generative-ai">What is Generative AI?</h3>
<p>Generative AI refers to a class of machine learning models that can generate new content, such as text, images, audio, and video. They learn the underlying patterns in training data and can create novel outputs that resemble that data.</p>
<h3 id="key-types-of-generative-models">Key Types of Generative Models</h3>
<ul>
<li><strong>Large Language Models (LLMs):</strong> Models trained on massive text datasets, capable of generating coherent and contextually relevant text, translations, code, and more. (Examples: GPT, Llama, Gemma, Claude).</li>
<li><strong>Diffusion Models:</strong> Used primarily for image generation. They learn to reverse a process of gradually adding noise to an image, allowing them to generate new images by starting from random noise and iteratively removing it. (Examples: Stable Diffusion, DALL-E 3, Imagen).</li>
<li><strong>Variational Autoencoders (VAEs):</strong> A type of neural network that learns a compressed, latent representation of data and can then generate new samples from that latent space.</li>
<li><strong>Generative Adversarial Networks (GANs):</strong> Consist of two networks, a generator and a discriminator, that compete against each other. The generator tries to create realistic data, while the discriminator tries to distinguish between real and generated data.</li>
</ul>
<h2 id="large-language-models-llms">Large Language Models (LLMs)</h2>
<h3 id="transformer-architecture">Transformer Architecture</h3>
<ul>
<li>Description: The dominant architecture for LLMs. Uses self-attention mechanisms to weigh the importance of different parts of the input sequence.</li>
<li>Key Components: Attention mechanisms, multi-head attention, encoder layers, decoder layers, feedforward networks, residual connections, layer normalization.</li>
<li>Key Advantages: Ability to capture long-range dependencies, parallelizable training.</li>
<li>Reference: <a href="https://arxiv.org/abs/1706.03762">Attention is All You Need (Vaswani et al., 2017)</a></li>
</ul>
<h3 id="attention-mechanism">Attention Mechanism</h3>
<ul>
<li>Description: Allows the model to focus on relevant parts of the input when processing each word or token.</li>
<li>Process: Calculating query, key, and value vectors; computing attention scores; weighting value vectors based on attention scores.</li>
<li>Reference: <a href="https://arxiv.org/abs/1706.03762">Attention is All You Need (Vaswani et al., 2017)</a></li>
</ul>
<h3 id="key-llm-families">Key LLM Families</h3>
<ul>
<li><strong>GPT (OpenAI):</strong> Proprietary models known for strong general-purpose language capabilities, few-shot learning, and scaling.<ul>
<li><a href="https://platform.openai.com/docs/models">OpenAI API Documentation</a></li>
</ul>
</li>
<li><strong>Llama (Meta):</strong> Open-source models allowing more transparency, customization, and local deployment.<ul>
<li><a href="https://ai.meta.com/research/llama/">Meta Llama</a></li>
</ul>
</li>
<li><strong>Gemma (Google):</strong> Open models from Google, designed for responsible AI development and deployment. Focuses on efficiency and performance.<ul>
<li><a href="https://ai.google.dev/gemma">Google AI Gemma</a></li>
</ul>
</li>
<li><strong>Claude (Anthropic):</strong> Proprietary models focused on safety and helpfulness.</li>
</ul>
<h2 id="fine-tuning-techniques">Fine-Tuning Techniques</h2>
<h3 id="supervised-fine-tuning-sft">Supervised Fine-Tuning (SFT)</h3>
<ul>
<li>Description: Training a pre-trained LLM on a labeled dataset to adapt it to a specific task (e.g., text summarization, question answering).</li>
<li>Process: Prepare a dataset of input-output pairs, train the model using a loss function that compares the predicted output to the ground truth output, adjust the model's weights to minimize the loss.</li>
</ul>
<h3 id="parameter-efficient-fine-tuning-peft">Parameter-Efficient Fine-Tuning (PEFT)</h3>
<ul>
<li>Description: Techniques to reduce the computational cost and memory requirements of fine-tuning large LLMs by only training a small subset of the model's parameters.</li>
<li>Key Techniques: LoRA, QLoRA, Adapters.</li>
</ul>
<h4 id="lora-low-rank-adaptation">LoRA (Low-Rank Adaptation)</h4>
<ul>
<li>Description: Freezes the pre-trained model weights and injects trainable low-rank matrices into each Transformer layer.</li>
<li>Advantages: Significantly reduces the number of trainable parameters, faster training, lower memory requirements.</li>
<li>Reference: <a href="https://arxiv.org/abs/2106.09690">LoRA: Low-Rank Adaptation of Large Language Models (Hu et al., 2021)</a></li>
</ul>
<h4 id="qlora-quantized-lora">QLoRA (Quantized LoRA)</h4>
<ul>
<li>Description: Combines LoRA with quantization techniques (e.g., 4-bit quantization) to further reduce memory footprint.</li>
<li>Advantages: Extremely memory-efficient, allows fine-tuning of very large models on consumer hardware.</li>
<li>Reference: <a href="https://arxiv.org/abs/2305.14314">QLORA: Efficient Finetuning of Quantized LLMs (Dettmers et al., 2023)</a></li>
</ul>
<h4 id="fine-tuning-with-unsloth">Fine-tuning with Unsloth</h4>
<ul>
<li>Description: Easy way to use QLoRA with speed improvements.<ul>
<li>Code Example:
<code>python
from unsloth import FastLanguageModel  
model, tokenizer = FastLanguageModel.from_pretrained(  
    model_name="&lt;MODEL_NAME&gt;", # Replace with your required data location  
    max_seq_length=2048,  
    load_in_4bit=True,  
    )</code></li>
</ul>
</li>
</ul>
<h2 id="prompt-engineering-techniques">Prompt Engineering Techniques</h2>
<ul>
<li>Zero-shot Prompting: Providing a prompt without any examples.</li>
<li>Few-shot Prompting: Providing a prompt with a few examples to guide the model.</li>
<li>Chain of Thought Prompting: Encouraging the model to reason step-by-step to improve complex reasoning tasks.<ul>
<li>Reference: <a href="https://arxiv.org/abs/2201.11903">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (Wei et al., 2022)</a></li>
</ul>
</li>
<li>Pydantic will help creating and validating the inputs and outputs in Pythonic way</li>
</ul>
<h2 id="multimodal-models">Multimodal Models</h2>
<h3 id="architectures">Architectures</h3>
<ul>
<li>Connectors/Fusion Modules: How vision, audio, and textual representations are combined (attention mechanisms, cross-attention).</li>
<li>Training Objectives: How these models are trained to align different modalities.</li>
</ul>
<h3 id="models">Models</h3>
<ul>
<li><strong>Gemini (Google):</strong> <a href="https://ai.google.dev/models/gemini">Google Documentation</a></li>
<li><strong>Stable Diffusion:</strong> <a href="https://stablediffusionweb.com/">Stable Diffusion Website</a></li>
</ul>
<h2 id="deployment-and-optimization">Deployment and Optimization</h2>
<h3 id="quantization">Quantization</h3>
<ul>
<li>Description: Reducing the precision of model weights (e.g., from 32-bit floats to 8-bit integers) to reduce model size and improve inference speed.</li>
<li>Techniques: Post-Training Quantization, Quantization-Aware Training (QAT)</li>
</ul>
<h3 id="knowledge-distillation">Knowledge Distillation</h3>
<ul>
<li>Description: Training a smaller "student" model to mimic the behavior of a larger "teacher" model.</li>
<li>Pros: Reduces model size and improves inference speed.</li>
</ul>
<h2 id="my-notes">My Notes</h2>
<p>(Add your own notes, code snippets, and explanations here.)</p>
<p>Here's a good resource on prompts to start with in LLM section: <a href="https://www.promptingguide.ai/">Prompt Engineering Guide</a></p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.c8b220af.min.js"></script>
      
    
  </body>
</html>